{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.    7.    9.    5.  ]\n",
      " [ 0.   -0.5  -1.5  -1.5 ]\n",
      " [ 0.   -0.75 -1.25 -1.25]\n",
      " [ 0.    1.75  2.25  4.25]]\n",
      "[[8. 7. 9. 5.]\n",
      " [4. 3. 3. 1.]\n",
      " [2. 1. 1. 0.]\n",
      " [6. 7. 9. 8.]]\n"
     ]
    }
   ],
   "source": [
    "# A = [[1., 0., 0., 0.],\n",
    "#          [-.5, 1., 0., 0.],\n",
    "#          [-.25, 0., 1., 0.], \n",
    "#          [-.75, 0., 0., 1.]]\n",
    "\n",
    "# B = [[8., 7., 9., 5.],\n",
    "#          [4., 3., 3., 1.],\n",
    "#          [2., 1., 1., 0.], \n",
    "#          [6., 7., 9., 8.]]\n",
    "\n",
    "# print(np.matrix(A)*np.matrix(B))\n",
    "\n",
    "# f = np.matrix([[8., 7., 9., 5.],\n",
    "#  [4., 3., 3., 1.],\n",
    "#  [2., 1., 1., 0.],\n",
    "#  [6., 7., 9., 8.]])\n",
    "\n",
    "# g = np.matrix([[ 1.,    0.,    0.,    0.  ],\n",
    "#  [-0.5,   1.,    0.,    0.,  ],\n",
    "#  [-0.25,  0.,    1.,    0.,  ],\n",
    "#  [-0.75,  0.,    0.,    1.,  ]])\n",
    "\n",
    "# print(np.eye(4)*f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take-Home Final - Computational Linear Algebra 373/574"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put my normal pre-exam stuff here**\n",
    "\n",
    "This exam was complete by _Rikki Shomer_\n",
    "\n",
    "_I have not given, recieved, nor tolerated others use of unauthorized aid on this exam._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - (15 pts) Extending the LU Decomposition Methods:\n",
    "\n",
    "### Part A \n",
    "(10pts) Modify the LU method from Rachel's lectures to add partial pivoting.  \n",
    "\n",
    "*Hint: the swap method below will be useful. Don't forget to run the cell before using the function.*\n",
    "\n",
    "**NOTE:** I am well aware that you can probably find LU with pivoting on Stack-Overflow. Two Comments:\n",
    "\n",
    "    1) If you get code from stack-overflow... be absolutely sure it works.\n",
    "    2) Make sure you MODIFY this function, that is, if you get whole-sale different code, I'll know it's not your work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "def LU(A):\n",
    "    U = np.copy(A)\n",
    "    m, n = A.shape\n",
    "    L = np.eye(n)\n",
    "    for k in range(n-1):\n",
    "        for j in range(k+1,n):\n",
    "            L[j,k] = U[j,k]/U[k,k]\n",
    "            U[j,k:n] -= L[j,k] * U[k,k:n]\n",
    "    return L, U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't forget to run this cell before using this function.\n",
    "def swap(a,b):\n",
    "    temp = np.copy(a)\n",
    "    a[:] = b\n",
    "    b[:] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LU_piv(A):\n",
    "    U = np.copy(A)\n",
    "    m, n = A.shape\n",
    "    L = np.eye(n)\n",
    "    P = np.copy(L)\n",
    "    \n",
    "    #Missing all the real code!\n",
    "    for k in range(n-1):\n",
    "        L_inc = np.eye(n)\n",
    "        \n",
    "        #find largest element in column below diagonal\n",
    "        pivot_idx = np.argmax(U[k+1:,k]) + k + 1\n",
    "        pivot = U[pivot_idx,k]\n",
    "        \n",
    "        #swap with pivot row\n",
    "        swap(P[k], P[pivot_idx])\n",
    "        swap(U[k], U[pivot_idx])\n",
    "        \n",
    "        #needs to be swapped with the prior L(k-1)\n",
    "        if (k > 0):\n",
    "            swap(L[k,:k], L[pivot_idx,:k])\n",
    "        \n",
    "        elim_vals = np.copy(U[k+1:,k]/pivot).flatten()\n",
    "        L[k+1:,k] = elim_vals\n",
    "        L_inc[k+1:,k] = -elim_vals\n",
    "\n",
    "        U = np.matrix(L_inc)*U\n",
    "        \n",
    "    return np.matrix(P), np.matrix(L), np.matrix(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Full--------------\n",
      "\n",
      "[[1. 0. 0. 0.]\n",
      " [2. 1. 0. 0.]\n",
      " [4. 3. 1. 0.]\n",
      " [3. 4. 1. 1.]]\n",
      "[[2. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 0. 2. 2.]\n",
      " [0. 0. 0. 2.]]\n",
      "\n",
      "\n",
      "----------Pivot-------------\n",
      "\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "[[ 1.          0.          0.          0.        ]\n",
      " [ 0.75        1.          0.          0.        ]\n",
      " [ 0.5        -0.28571429  1.          0.        ]\n",
      " [ 0.25       -0.42857143  0.33333333  1.        ]]\n",
      "[[ 8.          7.          9.          5.        ]\n",
      " [ 0.          1.75        2.25        4.25      ]\n",
      " [ 0.          0.         -0.85714286 -0.28571429]\n",
      " [ 0.          0.          0.          0.66666667]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Cell for including some test code of your LU with pivoting.\n",
    "\n",
    "Alist = [[2., 1., 1., 0.],\n",
    "         [4., 3., 3., 1.],\n",
    "         [8., 7., 9., 5.], \n",
    "         [6., 7., 9., 8.]]\n",
    "A = np.matrix(Alist)\n",
    "# scratch to test my array kerfuffle\n",
    "# ac = np.copy(A)\n",
    "# ac = ac[2:4,2] * ac[2:4,2]\n",
    "# print(ac)\n",
    "\n",
    "print(\"----------Full--------------\\n\")\n",
    "L,U = LU(A)\n",
    "print(L)\n",
    "print(U)\n",
    "\n",
    "print(\"\\n\\n----------Pivot-------------\\n\")\n",
    "\n",
    "P,L2,U2 = LU_piv(A)\n",
    "print(P)\n",
    "print(L2)\n",
    "print(U2)\n",
    "\n",
    "Atest = P.T*L2*U2\n",
    "\n",
    "print(np.allclose(Atest, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "(5 pts) Provide a **WRITTEN** explanation of how to modify your above algorithm to implement full pivoting. You do NOT need to code this (though you might want to, to confirm it works like you think it will). This should clearly be how to MODIFY YOUR EXISTING CODE. It should not simply be an explanation of what \"full pivoting\" is, though it should be clear from your explanation that you understand what full pivoting is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell to test (if needed) your full-pivot LU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 2: (5 pts each) Storage Formats\n",
    "Given the matrix:\n",
    "\n",
    "\\begin{pmatrix}\n",
    "  1 & & & & -2 & -3 \\\\\n",
    "  & 3 &  & & & -9 \\\\\n",
    "  &  &  & -7 & 4 & \\\\ \n",
    "  -1 & 2 & & 7 & & \\\\\n",
    "  -3 & & & 26 & &\n",
    " \\end{pmatrix}\n",
    " \n",
    "### Part A -- Write how this matrix would be stored in compressed **row** format.\n",
    "### Part B -- Write how this matrix would be stored in compressed **column** format.\n",
    "### Part C -- Write how this matrix would be stored in coordinate format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Answers:\n",
    "\n",
    "Parts A through C above all requisite we compute the SVD of the Given matrix A.\n",
    "Let us define the SVD matrix A to be: \n",
    "\n",
    "$A =U \\Sigma V_t$\n",
    "\n",
    "Where $A$ is the given matrix.  $U$ and $V$ are unitary matrics whose columns represent the eigenvectors of $A$, and $\\Sigma$ is a diagonal matrix whose values along the diagonal elements correspond to the eigenvalues of matrix $A$.  We also state $\\Sigma_v$ to be the vector of diagonal values in $\\Sigma$\n",
    "\n",
    "(_note_: $V_t$ is then said to have orthogonal ROW vectors) \n",
    "\n",
    "\n",
    "It follows then that we would be able to store a compressed version of the image with...\n",
    "    \n",
    "**Part A)**  \n",
    "...respect to its column space by simply storing $U$ and $\\Sigma_v$ \n",
    "\n",
    "**Part B)**  \n",
    "...respect to its row space by simply storing $V_t$ and $\\Sigma_v$  \n",
    "\n",
    "**Part C)**  \n",
    "asfdds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 - (30pts) Applying Least-Squares to real data.\n",
    "\n",
    "Below is a code-snippet that imports some hospital data, reduces it to the numerical attributes, then shows you the data summary and head of the files. Run this code snippet, examine the results, then look afterwards for the questions to answer.\n",
    "\n",
    "This data was retrieved from the CORGIS project: https://think.cs.vt.edu/corgis/csv/hospitals/hospitals.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable/Key Names in the (Reduced) Dataset:\n",
      " Index(['Cardiovascular', 'Eye', 'Gastrointestinal', 'Genitourinary',\n",
      "       'Musculoskeletal', 'Nervous System', 'Skin'],\n",
      "      dtype='object') \n",
      "\n",
      "Summary Statistics: \n",
      "        Cardiovascular            Eye  Gastrointestinal  Genitourinary  \\\n",
      "count     4861.000000    4861.000000       4861.000000    4861.000000   \n",
      "mean       609.459782     258.626209       1361.990125     285.108825   \n",
      "std      11366.625942    4971.204240       3359.573371    1111.837436   \n",
      "min          0.000000       0.000000          0.000000       0.000000   \n",
      "25%          0.000000       0.000000          0.000000       0.000000   \n",
      "50%          3.000000       0.000000        160.000000      13.000000   \n",
      "75%        183.000000     136.000000       1578.000000     263.000000   \n",
      "max     709791.000000  344180.000000     136890.000000   51083.000000   \n",
      "\n",
      "       Musculoskeletal  Nervous System          Skin  \n",
      "count      4861.000000     4861.000000   4861.000000  \n",
      "mean        520.420490      370.248714    489.725982  \n",
      "std        1524.703418     1724.903724   2152.847602  \n",
      "min           0.000000        0.000000      0.000000  \n",
      "25%           0.000000        0.000000      0.000000  \n",
      "50%          36.000000        0.000000      8.000000  \n",
      "75%         529.000000      171.000000    174.000000  \n",
      "max       44212.000000    79763.000000  65768.000000   \n",
      "\n",
      "Shape of data matrix:  (4861, 7)\n",
      "\n",
      " \n",
      " ---------------- \n",
      " \n",
      "\n",
      "First 5 lines of the pandas data-frame:\n",
      "    Cardiovascular  Eye  Gastrointestinal  Genitourinary  Musculoskeletal  \\\n",
      "0              14  244               395            113               76   \n",
      "1              80  874              5878            395             1046   \n",
      "2             159  287              1817            321              831   \n",
      "3            1076  384             12938            928              600   \n",
      "4             169    1              5383            407              102   \n",
      "\n",
      "   Nervous System  Skin  \n",
      "0             710    25  \n",
      "1            1841    64  \n",
      "2             139    41  \n",
      "3              35   104  \n",
      "4               8    40   \n",
      "\n",
      "Output of the numpy array:\n",
      " [[  14  244  395 ...   76  710   25]\n",
      " [  80  874 5878 ... 1046 1841   64]\n",
      " [ 159  287 1817 ...  831  139   41]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Read in the hospital data\n",
    "hospitals = pd.read_csv('hospitals.csv')\n",
    "#If you want to look at the full data-set you can.\n",
    "#print(hospitals.keys())\n",
    "#print(hospitals.describe())\n",
    "#print(hospitals.head())\n",
    "\n",
    "hospitals_reduced = hospitals.copy() #Make a copy to drop columns not needed for least squares fitting. \n",
    "hospitals_reduced = hospitals_reduced.drop(['Address', 'County', 'City', 'Phone Number', 'Ownership', 'Provider ID', 'State', 'Type', 'ZIP Code', 'Name', 'Longitude', 'Emergency Services', 'Latitude'], axis=1)\n",
    "\n",
    "#Turn it into a numpy array\n",
    "hospital_reduced_array = np.array(hospitals_reduced)\n",
    "\n",
    "#Output some summaries and data\n",
    "print(\"Variable/Key Names in the (Reduced) Dataset:\\n\", hospitals_reduced.keys(), \"\\n\")\n",
    "print(\"Summary Statistics: \\n\", hospitals_reduced.describe(), \"\\n\")\n",
    "print(\"Shape of data matrix: \", np.shape(hospital_reduced_array))\n",
    "\n",
    "print(\"\\n \\n ---------------- \\n \\n\")\n",
    "print(\"First 5 lines of the pandas data-frame:\\n\", hospitals_reduced.head(), \"\\n\")\n",
    "print(\"Output of the numpy array:\\n\", hospital_reduced_array, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the hospital data, perform a least-squares fit of two models for the relationship between 'Cardiovascular' operations and the other specializations. Some sklearn code is used below to provide you with test and training data split, as well as the target variables (split for training and testing).\n",
    "\n",
    "Model 1: Cardio (dependent variable) is related to the others using only FIRST-ORDER relationships (i.e. linear)\n",
    "\n",
    "Model 2: Cardio (dependent variable) is related to the others using FIRST and SECOND order relationships\n",
    "\n",
    "***Hint:*** *If you are stuck, look at the USF Notebook 5 and Videos CLA-8 S1+S2 for some hints on several of the sub-part below. This is an expansion on some of those processes, applied to a different data-set. You can resuse code from the USF Notebooks when appropriate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3888, 6), (973, 6))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "hospital_features_trn,hospital_features_test,hospital_target_trn,hospital_target_test = train_test_split(hospital_reduced_array[:,1:7], hospital_reduced_array[:,0], test_size=0.2)\n",
    "hospital_features_trn.shape, hospital_features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 - Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 2.16 ms\n",
      "\n",
      "mean absolute error (L1):   2395.39480042762\n",
      "mean squared norm (L2):   6617.439527839677 \n",
      "\n",
      "CPU times: user 15.6 ms, sys: 15.6 ms, total: 31.2 ms\n",
      "Wall time: 3.68 ms\n",
      "\n",
      "mean absolute error (L1):   2466.32764622198\n",
      "mean squared norm (L2):   29740.644488364676 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train and test the log reg   \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import math\n",
    "\n",
    "def error_foo(test, pred):\n",
    "    return (math.sqrt(mean_squared_error(test, pred)), \n",
    "            mean_absolute_error(test, pred))\n",
    "\n",
    "def display_Ls(test, pred):\n",
    "    (L2, L1) = error_foo(test, pred)\n",
    "    print(\"\\nmean absolute error (L1):  \", L1)\n",
    "    print(\"mean squared norm (L2):  \", L2, \"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "lr = LinearRegression()\n",
    "%time lr.fit(hospital_features_trn, hospital_target_trn)\n",
    "\n",
    "hospital_target_pred = lr.predict(hospital_features_test)\n",
    "display_Ls(hospital_target_test, hospital_target_pred)\n",
    "\n",
    "pr = LinearRegression()\n",
    "poly = PolynomialFeatures(include_bias=False)\n",
    "poly_fts_trn = poly.fit_transform(hospital_features_trn)\n",
    "\n",
    "%time pr.fit(poly_fts_trn, hospital_target_trn)\n",
    "\n",
    "poly_fts_test = poly.fit_transform(hospital_features_test)\n",
    "hospital_target_pred2 = pr.predict(poly_fts_test)\n",
    "display_Ls(hospital_target_test, hospital_target_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A -- Finding Decompositions -- 3 pts per model, per decomposition.\n",
    "\n",
    "Find the coefficients for both of these models using (Turn in the code, I recommend separate code-cells for each):\n",
    "\n",
    "    (a) A LU Decomposition\n",
    "    (b) A QR Decomposition\n",
    "    (c) A SVD Decomposition\n",
    "\n",
    "**NOTE: You do NOT need to write or use your own functions for these! You may use optimized/packaged routines. You do however need to provide code, including the package imports, of how to make use of standard routines.**\n",
    "\n",
    "**NOTE 2: You should try to only use packages that are installed in the base install of Anaconda, eg: numpy, pandas, sklearn, scipy, math etc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.11494962e-05 -1.30299043e+00  7.33727131e-01 -3.31861841e-02\n",
      "  5.52223942e+00  8.17685717e-01]\n",
      "[-0.00820285 -1.11528834  0.98284636 -0.48919536  5.2417941   0.56546641]\n",
      "[-0.00820285 -1.11528834  0.98284636 -0.48919536  5.2417941   0.56546641]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)\n",
    "data_matrix = hospital_reduced_array[:,1:7]\n",
    "target = hospital_reduced_array[:, 0]\n",
    "\n",
    "# (a) A LU Decomposition\n",
    "\n",
    "import scipy.linalg as la\n",
    "\n",
    "p,l,u = la.lu(data_matrix)\n",
    "pb = p * np.matrix(target).T\n",
    "y = la.lstsq(l,pb)[0]\n",
    "lu_coefs = la.solve_triangular(u,y)\n",
    "print(lu_coefs.flatten())\n",
    "\n",
    "\n",
    "# (b) A QR Decomposition\n",
    "\n",
    "\n",
    "\n",
    "# (c) A SVD Decomposition\n",
    "u, s, vt = la.svd(data_matrix)\n",
    "\n",
    "#A = USVt => b = USVt*x => Ut*b = SVt*x => (Ut*b)/S = Vt*x =>  (Vt)t*((Ut*b)/S) = x\n",
    "\n",
    "t1 = (u.T*target)\n",
    "# t2 = t1/s\n",
    "# svd_coefs = vt.T*t2\n",
    "# print(svd_coefs)\n",
    "def ls_svd(A,b):\n",
    "    m, n = A.shape\n",
    "    U, sigma, Vh = la.svd(A, full_matrices=False, lapack_driver='gesdd')\n",
    "    w = (U.T @ b)/ sigma\n",
    "    return Vh.T @ w\n",
    "\n",
    "\n",
    "print(ls_svd(data_matrix,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A - Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pr.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B -- Analysis of Outputs -- 6 pts each\n",
    "This quesiton will be graded on the quality of your explanations/comparisons, not on the accuracy (besides use of your numbers from above).\n",
    "\n",
    "Report in paragraphs explaining how to interpret the results:\n",
    "\n",
    "  1) A comparison of the time for each model, using each solution technique.\n",
    "  \n",
    "  The linear model (Model1) was fairly quick to execute as it only required approximately 10.6 ms.  However, the second order model (Model2) required ms.\n",
    "  \n",
    "  2) A comparison of the L1 & L2 accuracy, using each solution technique. \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Problem (10 pts) Add shifts to the QR algorithm\n",
    "\n",
    "Instead of factoring $A_k$ as $Q_k R_k$ (the way the pure QR algorithm without shifts does), the shifted QR algorithm:\n",
    "\n",
    "i. Chooses/Finds $s_k = A_k(m,m)$, an approximation of an eigenvalue of A.\n",
    "\n",
    "ii. Gets the QR factorization $$A_k - s_k I = Q_k R_k$$\n",
    "\n",
    "iii. Sets $$A_{k+1} = R_k Q_k + s_k I$$\n",
    "\n",
    "*Hint: If you aren't sure how to get an eigenvalue approximation, one option is to look back at the truncated/randomized SVD processes. What's the relationship between the first singular value in that process and the eigenvalues of A? What is the relationship between SVD and QR?*\n",
    "\n",
    "The idea of adding shifts to speed up convergence shows up in many algorithms in numerical linear algebra (including the power method, inverse iteration, and Rayleigh quotient iteration).  The real way this would work is through using additional mathematics of Hessenberg matrices and Householder transformations (from which the eigen-value approximations come as part of the iterative process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def practical_qr(A, iters=10):\n",
    "    # Fill method in\n",
    "    return Ak, Q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
